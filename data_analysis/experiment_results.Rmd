---
title: "Model-assisted forecasting: experiments analyses"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


``` {r}
# Load packages
library(dplyr)
library(emmeans)
library(lme4)
library(lmerTest)
library(here)
library(ltm)
library(glmnet)
library(ggplot2)
library(stringi)
library(lubridate)
source('multi-choice-utils.R')
```


``` {r}
# Set up tableau color palette
tableau_palette = c("#4E79A7","#F28E2B","#E15759","#76B7B2","#59A14F","#EDC948","#B07AA1","#FF9DA7","#9C755F","#BAB0AC")

```


``` {r}

raw_experiment_data = read.csv('../experiment_data/raw_experiment_data.csv')

bad_workers = raw_experiment_data %>%
  group_by(workerId_hash) %>%
  summarize(
    n=n()
  ) %>%
  subset(n != 48)

experiment_data = raw_experiment_data %>%
  subset(!(workerId_hash %in% bad_workers$workerId_hash)) %>%
  identify_junk() %>%
  subset(is_practice == "False") %>%
  subset(passed_check == T) %>%
  mutate(
    trial_id =  paste(workerId_hash,hitId,predictor_city,sep='-'),
    year = 2023,
  ) %>%
  threshold_estimates()

bad_trials = experiment_data %>%
  group_by(trial_id) %>%
  summarize(num_temps = length(unique(temperature_estimate))) %>%
  subset(num_temps <= 2) %>%
  pull(trial_id) %>%
  unique()


experiment_data = experiment_data %>%
    mutate(
    bad_trial = trial_id %in% bad_trials,
    adjusted_temperature_estimate = case_when(
      bad_trial ~ temperature_estimate + rnorm(n(),0,0.01),
      TRUE ~ as.double(temperature_estimate)
    )
  ) %>%
  add_bootstrapping_estimates(4,F) %>%
  mutate(
      type = case_when(
        type == 'challenging' ~ 'Challenging',
        type == 'kind' ~ 'Kind',
        type == 'wicked' ~ 'Wicked'
      ),
      type = factor(type,levels=c('Kind','Challenging','Wicked'))
  )


kind_cities = c('Baltimore', 'Charlotte', 'Denver', 'Orlando', 'Portland', 'Sacramento', 'San Antonio', 'St. Louis')
challenging_cities = c('Cairo', 'Delhi', 'Lagos', 'London', 'Mexico City', 'Paris', 'Tokyo', 'Toronto')
wicked_cities = c('Auckland', 'Buenos Aires', 'Johannesburg', 'Luanda', 'Lima', 'Sao Paulo', 'Sydney', 'Santiago')
all_cities = c(kind_cities,challenging_cities,wicked_cities)
experiment_data$ordered_predictor_city = factor(experiment_data$predictor_city,levels=all_cities)

```




``` {r fig.width = 8, fig.height = 5}
# Look at effects of data exclusion on Berlin

# First, get true answers for Berlin
berlin_averages = get_city_averages('Berlin')

# Plot raw estimates
raw_experiment_data %>%
  mutate(month=as.factor(month)) %>%
  subset(!(workerId_hash %in% bad_workers$workerId_hash)) %>%
  identify_junk() %>%
  subset(predictor_city == 'Berlin') %>%
  ggplot(aes(x=month,y=temperature_estimate,group=workerId_hash,color=passed_check)) +
  geom_line(alpha=0.07) +
  ylim(0,120) +
  geom_line(data=berlin_averages,aes(x=month,y=average_hi,group=city,color='truth'),size=1,color='black') +
  labs(
    x='Month',
    y='Temperature estimate',
    title='Temperature estimates on Berlin based on filtering criteria',
    color = "Passed Berlin filter"
  )

```



``` {r fig.width = 5, fig.height = 5}

# Look at average error based on whether participant passed Berlin

# Average error by whether or not they passed check
raw_experiment_data %>%
  identify_junk() %>%
  subset(predictor_city != 'Berlin') %>%
  group_by(passed_check) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n())
  ) %>%
  ggplot(aes(x=passed_check,y=average_error,fill=passed_check)) +
  geom_bar(stat='identity') +
  geom_errorbar(aes(ymin=average_error-error_se,
                    ymax=average_error+error_se),
                width=0.2,size=1)+
  labs(
    x='Passed attention check',
    y='Mean absolute error',
    fill = "Passed Berlin filter"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

```

``` {r}
# Look at effects of data exclusion on Berlin
# Get number of people that failed the "bot check" of all 99 degrees
bots = raw_experiment_data %>%
  subset(predictor_city == 'Berlin') %>%
  group_by(workerId_hash) %>%
  summarize(
    num_unique_estimates = length(unique(temperature_estimate)),
    average_temp_prediction = mean(temperature_estimate)
  ) %>%
  subset(num_unique_estimates == 1) %>%
  subset(average_temp_prediction == 99)


print(paste(c('Num failed bot check',nrow(bots))))

# No participants answered 99 for every problem

```


``` {r fig.width = 10, fig.height = 10}
# Estimate abilities from IRT model and add to experiment_data

# Prep worker data and irt data

# Add worker data to 
worker_data = data.frame()
for (hit in experiment_hits){
  filepath = paste0('../experiment_data/',hit,'/worker_data.csv')
  curr_data = filepath %>%
    read.csv()
  worker_data = rbind(worker_data,curr_data)
}

worker_data = worker_data %>%
  subset(workerId_hash %in% unique(experiment_data$workerId_hash))

irt_data = dplyr::select(worker_data,matches("correct"))
irt_data = irt_data[,order(colnames(irt_data))]
irt_data = data.frame(sapply(irt_data, \(x) +as.logical(x)))

# Convert to 0/1
#irt_model = ltm(irt_data ~ z1)
irt_model = tpm(irt_data) # Three-parameter model
# irt_model_og = ltm(irt_data ~ z1)
# Correlate scores from both models...

# og_ability = factor.scores(irt_model_og, resp.patterns = irt_data)$score.dat$z1
# new_ability =  factor.scores(irt_model, resp.patterns = irt_data)$score.dat$z1

# plot(og_ability,new_ability)

worker_data$ability = factor.scores(irt_model, resp.patterns = irt_data)$score.dat$z1
worker_data$num_correct = rowSums(irt_data)

# Merge worker data with experiment_test
experiment_data = experiment_data %>%
  merge(worker_data,by='workerId_hash',all.x=T)

plot(irt_model,type="ICC")

```


``` {r fig.width = 5, fig.height = 6}
# Look at overall error rates: bar plot
experiment_data %>%
  group_by(model_assistance) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()) 
  ) %>%
  ggplot(aes(x=model_assistance,y=average_error,fill=model_assistance)) +
  geom_bar(stat='identity') +
  geom_errorbar(aes(ymin=average_error - error_se,ymax = average_error+error_se),
                size=1,width=0.27) +
  labs(
    x='Model assistance',
    y='Mean absolute error',
    title='Overall error rates by condition'
  ) + 
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )

```


``` {r fig.width = 5, fig.height = 6}

# Look at overall error rates: Participant averages
experiment_data %>%
  group_by(model_assistance,workerId_hash) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()) 
  ) %>%
  mutate(
    x_vals = runif(n(),0,1),
    x_vals = ifelse(model_assistance=="False",x_vals,x_vals+1.25)
  ) %>%
  ggplot(aes(x=x_vals,y=average_error,color=model_assistance,fill=model_assistance)) +
  geom_point(alpha=0.35) +
  #geom_errorbar(aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.035,alpha=0.35) +
  labs(
    x='Model assistance',
    y='Mean absolute error',
    title='Overall error rates by condition\nPoints are individual participants'
  ) +
  # geom_violin(alpha=0.25) +
  # geom_point(data=overall_error_rates,size=4) + 
  # geom_errorbar(data=overall_error_rates,
  #               aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.02,size=1) +
  scale_x_continuous(breaks=c(0.5,1.75),labels=c("False","True")) + 
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )
  
```



``` {r fig.width = 5, fig.height = 6}


overall_error_rates = experiment_data %>%
  group_by(model_assistance) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()),
  )

overall_error_rates$x_vals = ifelse(overall_error_rates$model_assistance=="False",0.5,1.75)

# Look at overall error rates: Participant averages
experiment_data %>%
  group_by(model_assistance,workerId_hash) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()) 
  ) %>%
  mutate(
    x_vals = runif(n(),0,1),
    x_vals = ifelse(model_assistance=="False",x_vals,x_vals+1.25)
  ) %>%
  ggplot(aes(x=x_vals,y=average_error,color=model_assistance,fill=model_assistance)) +
  geom_point(alpha=0.125) +
  # geom_errorbar(aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.03,alpha=0.3) +
  labs(
    x='Model assistance',
    y='Mean absolute error',
    title='Overall error rates by condition\nSmall points are individual participants\nLarge points show overall means'
  ) +
  geom_point(data=overall_error_rates,size=3,shape = 15) + 
  geom_errorbar(data=overall_error_rates,
                aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.1,size=1) +
  scale_x_continuous(breaks=c(0.5,1.75),labels=c("False","True")) + 
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )
  
```



``` {r fig.width = 5, fig.height = 6}

overall_error_rates = experiment_data %>%
  group_by(model_assistance) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()),
    x_vals = ifelse(model_assistance=="False",0.5,1.75)

  )

# Look at overall error rates: Participant averages
experiment_data %>%
  group_by(model_assistance,workerId_hash) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()) 
  ) %>%
  mutate(
    x_vals = runif(n(),0,1),
    x_vals = ifelse(model_assistance=="False",x_vals,x_vals+1.25)
  ) %>%
  ggplot(aes(x=x_vals,y=average_error,color=model_assistance,fill=model_assistance)) +
  geom_point(alpha=0.125) +
  # geom_errorbar(aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.03,alpha=0.3) +
  labs(
    x='Model assistance',
    y='Mean absolute error',
    title='Overall error rates by condition\nSmall points are individual participants\nLarge points show overall means'
  ) +
  geom_violin(alpha=0.1) +
  geom_point(data=overall_error_rates,size=3,shape = 15) + 
  geom_errorbar(data=overall_error_rates,
                aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.1,size=1) +
  scale_x_continuous(breaks=c(0.5,1.75),labels=c("False","True")) + 
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )
  
```



``` {r fig.width = 8, fig.height = 6}
# Look at overall error rates by type: bar plot
experiment_data %>%
  group_by(model_assistance,type) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()) 
  ) %>%
  ggplot(aes(x=type,y=average_error,fill=model_assistance)) +
  geom_bar(stat='identity',position=position_dodge(0.9)) +
  geom_errorbar(aes(ymin=average_error - error_se,ymax = average_error+error_se),
                size=1,width=0.4,position=position_dodge(0.9)) +
  labs(
    x='Trial difficulty',
    y='Mean absolute error',
    title='Overall error rates by condition and difficulty',
    fill = "Model assistance"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )


```



``` {r fig.width = 7, fig.height = 7}

overall_error_rates_by_condition = experiment_data %>%
  group_by(model_assistance,type) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()),
    x_vals = ifelse(model_assistance=="False",0.5,1.75)
  )

# Look at overall error rates: Participant averages
experiment_data %>%
  group_by(model_assistance,workerId_hash,type) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()) 
  ) %>%
  mutate(
    x_vals = runif(n(),0,1),
    x_vals = ifelse(model_assistance=="False",x_vals,x_vals+1.25)
  ) %>%
  ggplot(aes(x=x_vals,y=average_error,color=model_assistance)) +
  geom_jitter(alpha=0.12) +
  facet_grid(cols=vars(type)) +
  labs(
    x='Model assistance',
    y='Mean absolute error',
    title="Overall error rates by condition and difficulty\nEach point is one participant's estimates"
  ) +
  geom_point(data=overall_error_rates_by_condition,size=3,shape = 15) + 
  geom_errorbar(data=overall_error_rates_by_condition,
                aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.2,size=1) +
  scale_x_continuous(breaks=c(0.5,1.75),labels=c("False","True")) + 
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5),
    strip.background = element_blank()
  )
  
```




``` {r fig.width = 7, fig.height = 7}

# Same as above but with violin plots
overall_error_rates_by_condition = experiment_data %>%
  group_by(model_assistance,type) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()),
  )

overall_error_rates_by_condition$x_vals = ifelse(overall_error_rates_by_condition$model_assistance=="False",0.5,1.75)
overall_error_rates_by_condition$condition = ifelse(overall_error_rates_by_condition$model_assistance=="False",'Control','Model\nassistance')


# Look at overall error rates: Participant averages
plot = experiment_data %>%
  group_by(model_assistance,workerId_hash,type) %>%
  summarize(
    average_error = mean(abs_error),
    error_se = se(abs_error,n()),
    condition = ifelse(model_assistance == 'False','Control','Model\nassistance')
  ) %>%
  mutate(
    x_vals = runif(n(),0,1),
    x_vals = ifelse(model_assistance=="False",x_vals,x_vals+1.25)
  ) %>%
  ggplot(aes(x=x_vals,y=average_error,color=condition)) +
  scale_fill_manual(values = tableau_palette) +
  scale_color_manual(values = tableau_palette) +
  geom_jitter(alpha=0.012,size=0.7)+
  facet_grid(cols=vars(type)) +
  labs(x='Condition',y='Mean absolute error',) +
  geom_violin(alpha=0) +
  geom_point(data=overall_error_rates_by_condition,size=3,shape = 15) + 
  geom_errorbar(data=overall_error_rates_by_condition,
                aes(ymin=average_error-error_se,ymax=average_error+error_se),width=0.24,size=1) +
  scale_x_continuous(breaks=c(0.5,1.75),labels=c("Control","Model\nassistance")) + 
  theme_classic() +
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5),
    strip.background = element_blank()
  ) 
  
ggsave("final_plots/overall_error_rates.pdf", plot, width = 8, height = 4, units = "in")

```


``` {r fig.width = 9, fig.height = 7}
city_data = experiment_data %>%
  group_by(model_assistance,type,ordered_predictor_city) %>%
  summarize(
    average_error = mean(abs_error),
    average_error_se = se(abs_error,n())
  ) 

city_data %>%
  ggplot(aes(x=model_assistance,y=average_error,color=model_assistance)) +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=average_error-average_error_se,ymax=average_error+average_error_se),
                width=0.33,size=1) +
  facet_wrap(. ~ ordered_predictor_city,ncol=8) +
  geom_rect(data = city_data,aes(fill = type),xmin = -Inf,xmax = Inf,
            ymin = -Inf,ymax = Inf,alpha = 0.1) +
  scale_fill_manual(values=c('green','blue','red')) +
  labs(
    x="Model assistance",
    y='Mean absolute error',
    fill = 'Difficulty',
    color='Model assistance',
  ) +
  theme(
    legend.position='bottom'
  )

```


``` {r fig.width = 9, fig.height = 7}
city_data %>%
  ggplot(aes(x=model_assistance,y=average_error,color=model_assistance)) +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=average_error-average_error_se,ymax=average_error+average_error_se),
                width=0.33,size=1) +
  facet_wrap(. ~ ordered_predictor_city,ncol=8) +
  labs(
    x="Model assistance",
    y='Mean absolute error',
    color='Model assistance'
  ) +
  theme(
    legend.position='bottom'
  )

```


``` {r fig.width = 10, fig.height = 7}
# Spaghetti plots: All passed check
predictor_city_highs = get_city_averages(unique(subset(experiment_data,model_assistance == "True")$predictor_city))

most_popular_model_city_highs = get_most_popular_model_cities(experiment_data) %>%
  mutate(
    city = factor(predictor_city,levels=all_cities),
    most_popular_model_city = case_when(
      most_popular_model_city == 'San Francisco' ~ 'SF',
      most_popular_model_city == 'New York' ~ 'NYC',
      most_popular_model_city == 'Washington' ~ 'DC',
      most_popular_model_city == 'Los Angeles' ~ 'LA',
      most_popular_model_city == 'Philadelphia' ~ 'Philly',
      most_popular_model_city == 'Minneapolis' ~ 'MPLS',
      T ~ most_popular_model_city
    )
  )

best_model_city_highs = get_best_model_cities(experiment_data) %>%
  mutate(
    city = factor(predictor_city,levels=all_cities),
    best_model_city = case_when(
      best_model_city == 'San Francisco' ~ 'SF',
      best_model_city == 'New York' ~ 'NYC',
      best_model_city == 'Washington' ~ 'DC',
      best_model_city == 'Los Angeles' ~ 'LA',
      best_model_city == 'Philadelphia' ~ 'Philly',
      best_model_city == 'Minneapolis' ~ 'MPLS',
      T ~ best_model_city
    )
  )

predictor_city_highs %>%
  mutate(city = factor(city,levels=all_cities)) %>%
  ggplot(aes(x=month,y=average_hi)) +
  geom_line(size=1,color='black',alpha=0.5) +
  geom_line(size=1,data=most_popular_model_city_highs,aes(x=month,y=model_city_modeled_high),
    color='#dc143c',alpha=0.5)+
  geom_text(
    data=subset(most_popular_model_city_highs,month==2),
    aes(x=3.5,y=100,label=most_popular_model_city),
    color='#dc143c')+
  geom_line(size=1,data=best_model_city_highs,aes(x=month,y=best_model_predicted_hi),
    color='#1e90ff',alpha=0.5)+
  geom_text(
    data=subset(best_model_city_highs,month==10),
    aes(x=6.5,y=40,label=best_model_city),
    color='#1e90ff')+
  scale_x_continuous(breaks=c(2,4,6,8,10,12)) +
  facet_wrap(.~city,ncol=8) +
  labs(
    y='Temperature estimate',
    x='Month',
    title='Best (blue) and most popular (red) model city for each target city (black)'
  )
  theme(
    legend.position="bottom",
    plot.title = element_text(hjust = 0.5)
  )

```


``` {r fig.width = 14, fig.height = 7}
# Grouped experiment data
chosen_cities = experiment_data %>%
  subset(model_assistance == 'True') %>%
  group_by(ordered_predictor_city,model_city) %>%
  count()


# calculate the probability of each category within each group
chosen_city_probs = chosen_cities %>%
  group_by(ordered_predictor_city) %>%
  mutate(prob = n / sum(n))
  

# Plot chosen cities for each target city
chosen_city_probs %>%
  subset(prob != 0) %>%
  mutate(
    model_city = case_when(
      model_city == 'San Francisco' ~ 'SF',
      model_city == 'New York' ~ 'NYC',
      model_city == 'Washington' ~ 'DC',
      model_city == 'Los Angeles' ~ 'LA',
      model_city == 'Philadelphia' ~ 'Philly',
      model_city == 'Minneapolis' ~ 'MPLS',
      T ~ model_city
    )
  ) %>%
  ggplot(aes(x=model_city,y=prob)) +
  geom_bar(stat='identity') +
  facet_wrap(.~ordered_predictor_city,scales='free_x',ncol=8) +
  scale_y_continuous(breaks=c(0.1,0.2,0.3,0.4)) +
  labs(
    y='Proportion of trials with model city chosen',
    x='Target city',
    title='Distribution of chosen model cities for each target city'
  ) +
  theme(
    axis.text.x = element_text(angle = 90,vjust = 0.5, hjust=1),
    legend.position='bottom'
  )

  
```

``` {r fig.width = 11, fig.height = 8}
# Temperature curves for each city
experiment_data %>%
  mutate(
    city=ordered_predictor_city,
    city=factor(city,levels=all_cities)
  ) %>%
  group_by(model_assistance,city,month) %>%
  ggplot(aes(x=month,y=temperature_estimate,color=model_assistance,group=workerId_hash)) +
  geom_line(alpha=0.125) +
  geom_line(data=predictor_city_highs,aes(x=month,y=average_hi,group=1),color='black',alpha=0.75) +
  facet_wrap(.~city,ncol=8) +
  scale_x_continuous(breaks=c(2,4,6,8,10,12))+
  labs(
      y='Temperature estimate',
      x='Month',
      title="Temperature estimates\nEach curve is one participant's estimates\nBlack lines show the true averages",
      color = 'Model assistance'
  ) +
  theme(
    legend.position='bottom',
    plot.title = element_text(hjust = 0.5)
  )

```


``` {r fig.width = 8, fig.height = 6}
# Plot ability on x axis, and average error on y axis
experiment_data %>%
  group_by(workerId_hash,model_assistance) %>%
  summarize(
    ability = mean(ability),
    average_error = mean(abs_error)
  ) %>%
  ggplot(aes(x=ability,y=average_error,color=model_assistance)) +
  geom_point(alpha=0.15) +
  stat_smooth(geom="line", alpha=0.75,size=1.75) +
  labs(
    x = 'Estimated ability from IRT model',
    y='Mean absolute error',
    title = 'Mean absolute error by estimated ability\nEach point is one participant',
    color = 'Model assistance'
    
  ) +
  theme(
    # legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )

```





``` {r fig.width = 9, fig.height = 5}
# Plot ability on x axis, and average error on y axis
experiment_data %>%
  group_by(workerId_hash,model_assistance,type) %>%
  summarize(
    ability = mean(ability),
    average_error = mean(abs_error)
  ) %>%
  ggplot(aes(x=ability,y=average_error,color=model_assistance)) +
  geom_point(alpha=0.15) +
  stat_smooth(geom="line", alpha=0.75,size=1.75) +
  labs(
    x = 'Estimated ability from IRT model',
    y='Mean absolute error',
    title = 'Mean absolute error by estimated ability for each difficulty\nEach point is one participant',
    color = 'Model assistance'
    
  ) +
  facet_grid(cols=vars(type)) +
  theme(
    # legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )

```




``` {r fig.width = 7, fig.height = 6}
# Plot overall bootstrapping and human errors

human_forecasts = experiment_data %>%
  transmute(
    model_assistance ,
    error = abs_error,
    type,
    ordered_predictor_city,
    predictor_type = 'Human'
  )

bootstrap_forecasts = experiment_data %>%
  transmute(
    model_assistance,
    error = bootstrap_error,
    type,
    ordered_predictor_city,
    predictor_type = 'Bootstrap'
  )

errors_df = rbind(human_forecasts,bootstrap_forecasts) %>%
  mutate(predictor_type = factor(predictor_type,levels=c('Human','Bootstrap')))


errors_df %>%
  group_by(model_assistance,predictor_type) %>%
  summarize(
    average_error = mean(error),
    error_se = se(error,n())
  ) %>%
  ggplot(aes(x=model_assistance,y=average_error,fill=predictor_type)) +
  geom_bar(stat='identity',position=position_dodge(0.9)) +
  geom_errorbar(aes(ymin=average_error - error_se,ymax = average_error+error_se),
                size=1,width=0.3,position=position_dodge(0.9)) +
  labs(
    x = 'Model assistance',
    y='Mean absolute error',
    title = 'Mean absolute error\nHumans vs. bootstrapped estimates by condition',
    fill='Predictor type'
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

```



``` {r fig.width = 9, fig.height = 7}
# Plot overall bootstrapping and human errors

errors_df %>%
  group_by(model_assistance,predictor_type,type) %>%
  summarize(
    average_error = mean(error),
    error_se = se(error,n())
  ) %>%
  ggplot(aes(x=model_assistance,y=average_error,fill=predictor_type)) +
  geom_bar(stat='identity',position=position_dodge(0.9)) +
  geom_errorbar(aes(ymin=average_error - error_se,ymax = average_error+error_se),
                size=1,width=0.4,position=position_dodge(0.9)) +
  labs(
    x = 'Model assistance',
    y='Mean absolute error',
    title = 'Mean absolute error\nHumans vs. bootstrapped estimates by condition',
    fill='Predictor type'
  ) +
  facet_grid(cols=vars(type)) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

```


``` {r fig.width = 10, fig.height = 8}
# Plot chosen cities for each target city
errors_df %>%
  subset(model_assistance=='False') %>%
  group_by(predictor_type,ordered_predictor_city) %>%
  summarize(
    average_error = mean(error),
    error_se = se(error,n())
  ) %>%
  mutate(predictor_type = factor(predictor_type,levels=c('Human','Bootstrap'))) %>%
  ggplot(aes(x=predictor_type,y=average_error,color=predictor_type)) +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=average_error - error_se,ymax = average_error+error_se),size=1,width=0.3) +
  labs(
    x = 'Model assistance',
    y='Mean absolute error',
    title = 'Mean absolute error\nHumans vs. bootstrapped estimates by city\nNo model assistance only',
    color='Predictor type'
  ) +
  facet_wrap(.~ordered_predictor_city,ncol=8) +
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )
```


``` {r fig.width = 10, fig.height = 8}
# Plot chosen cities for each target city
errors_df %>%
  subset(model_assistance=='True') %>%
  group_by(predictor_type,ordered_predictor_city) %>%
  summarize(
    average_error = mean(error),
    error_se = se(error,n())
  ) %>%
  mutate(predictor_type = factor(predictor_type,levels=c('Human','Bootstrap'))) %>%
  ggplot(aes(x=predictor_type,y=average_error,color=predictor_type)) +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=average_error - error_se,ymax = average_error+error_se),size=1,width=0.3) +
  labs(
    x = 'Model assistance',
    y='Mean absolute error',
    title = 'Mean absolute error\nHumans vs. bootstrapped estimates by city\nModel assistance only',
    color='Predictor type'
  ) +
  facet_wrap(.~ordered_predictor_city,ncol=8) +
  theme(
    legend.position = 'none',
    plot.title = element_text(hjust = 0.5)
  )

```





``` {r fig.width = 8, fig.height = 7}
# Plot chosen cities for each target city
errors_df %>%
  group_by(predictor_type,ordered_predictor_city,type,model_assistance) %>%
  summarize(
    average_error = mean(error),
    error_se = se(error,n())
  ) %>%
  mutate(predictor_type = factor(predictor_type,levels=c('Human','Bootstrap'))) %>%
  ggplot(aes(x=model_assistance,y=average_error,fill=predictor_type)) +
  geom_bar(stat='identity',position=position_dodge(0.9)) +
  geom_errorbar(aes(ymin=average_error - error_se,ymax = average_error+error_se),width=0.35,position=position_dodge(0.9)) +
  labs(
    x = 'Model assistance',
    y='Mean absolute error',
    title = 'Mean absolute error\nHumans vs. bootstrapped estimates by city',
    fill='Predictor type',
  ) +
  facet_wrap(.~ordered_predictor_city,ncol=8) +
  theme(
    legend.position="bottom",
    plot.title = element_text(hjust = 0.5)
  )




```



``` {r}
# Do preregistered analyses

# H1: Error in kind < error in challenging; error in wicked > error in challenging
model0 = lmer(abs_error ~ type + (1|workerId_hash), data = experiment_data)
means0 = emmeans(model0,'type')
h1_tests = list(
  'challenging - kind' = c(-1,1,0),
  'wicked - challenging' = c(0,-1,1)
)
h1_contrasts = data.frame(contrast(means0,h1_tests))


model1 = lmer(abs_error ~ condition*type + 
                (1|workerId_hash) + (1|predictor_city) + 
                (1|workerId_hash:predictor_city), data = experiment_data)
means1 = emmeans(model1,c('type','condition'))
      
# H2: Compare overall errors in model assistance and control
h2_tests = list('control - model assistance' = c(1,1,1,-1,-1,-1)/3)
h2_contrasts = data.frame(contrast(means1,h2_tests))

experiment_data %>% 
  group_by(condition) %>%
  summarize(
    average_error = mean(abs_error)
  )

h3_tests = list(
  'Kind: Control - MA' = c(0,1,0,0,-1,0),
  'Challenging: Control - MA' = c(1,0,0,-1,0,0),
  'Wicked: Control - MA' = c(0,0,1,0,0,-1)
  )
      
h3_contrasts = data.frame((contrast(means1,h3_tests)))
h3_significant = sum(h3_contrasts$p.value < 0.05) == nrow(h1_contrasts)

experiment_data %>% 
  group_by(condition,type) %>%
  summarize(
    average_error = round(mean(abs_error),2)
  )





# H4: Compare bootstrap vs. human errors in both conditions
h4_model = lmer(human_minus_bootstrap_error ~ condition + (1|trial_id),data=experiment_data)
h4_means = emmeans(h4_model,'condition', lmer.df = "asymp")
h4_tests = list(
  'control' = c(1,0),
  'model assistance' = c(0,1)
)
  
# H4 results
h4_contrasts = data.frame((contrast(h4_means,h4_tests)))

experiment_data %>%
  group_by(condition) %>%
  summarize(
    average_error_reduction = round(mean(human_minus_bootstrap_error),2)
  )

```





``` {r}
# Calculate hourly wage


# experiment_hits

# Loop through experiment hits
all_worker_data = data.frame()
for (hit_i in experiment_hits){
  file_string = paste0('../experiment_data/',hit_i,'/worker_data.csv')
  worker_data = read.csv(file_string)
  all_worker_data = rbind(all_worker_data,worker_data)
}

all_worker_data$start_time_date = ymd_hms(all_worker_data$first_page_submit_time)
all_worker_data$end_time_date = ymd_hms(all_worker_data$end_time)
all_worker_data$experiment_duration = all_worker_data$end_time_date-all_worker_data$start_time_date

all_worker_data$wage = (1/as.numeric(all_worker_data$experiment_duration / 60)) * 1.5



```















